\chapter{EXPERIMENTAL PIPELINE}
\label{ch:experiments}


\section{Global Volume Registration and Motion Correction}

Both volume registration techniques described in Chapter \ref{ch:methods} were applied independently to each image from the subject cohorts described in Chapter \ref{ch:data}. After registration, three versions of each image existed: the original BOLD sequence, the sequence modified using traditional volume registration, and the sequence modified using the novel registration method.

The registration algorithms both used a combination of affine and nonlinear transformations to align each pair of image volumes. During the registration, the following registration parameters were used:
\begin{itemize}
\item Interpolation type: nearest neighbor
\item Number of threads: 100
\item Registration metric: cross correlation.
\end{itemize}

After both volume registration techniques were applied to each image, the registered sequences underwent motion correction via a well-established motion correction pipeline. We chose to use the independent component analysis (ICA) pipeline outlined by Beckmann and Smith and implemented as FMRIB's MELODIC tool \cite{Beckmann2004}. The motion corrected sequences produced by MELODIC were saved alongside the original and registered sequences. 

% NEEDS HELP
The original, registered, and motion corrected sequences were all compared to the Power et al. usability thresholds. The amount of motion removed from an image can be quantified using the FD and DVARS usability thresholds, but that analysis does not explain how volume registration and motion correction techniques generalize to larger populations. Other metrics including the correlation ratio matrix were calculated for each version of the sequence.

The differences between patient motion in the original and registered sequences were compared to these thresholds in a small evaluation of the immediate impact of registration algorithm on the image sequence. It is highly unlikely that an entire image sequence would meet the Power et al. usability thresholds after only the initial step of a motion correction pipeline, but it is valuable to examine the impact of a volume registration algorithm at each stage of the pipeline. 

%The results of this experiment show how the DAG-based framework fits into an existing, comprehensive motion correction pipeline. 

\section{Analyzing Patient Motion}

The metrics described in the previous section are strong alternatives to the FD and DVARs metrics 

Statistical analyses can be used to identify general trends within a data set. Statistical tests can be used to compare images before and after motion correction within each subject population. They can also indicate the degree of significance of the effects of volume registration and motion correction. 

\textbf{What statistical tests can be used to compare signals?}

\section{Patient Classification Using Motion Patterns} 

%Machine learning techniques can be used to classify images as belonging to different groups, but many of these techniques use difficult to interpret ``black box'' logic. In some cases, examining the logic behind a classification reveals patterns in a dataset which a human missed but a computer detected. These patterns can be helpful for improving human classification of the images, but they may also be based on artifacts which were not filtered out during preprocessing.

We suggest that the ways that patients move are specific to certain age groups. For example, fetal patients live suspended in amniotic fluid and as such are subject to different physical constraints than patients in other age groups. Neonatal patients are often scanned using a ``feed and bundle'' protocol, which often results in them sleeping through the scan. However, neonatal patients sometimes wake up during the scan, and the way a baby woken up from a nap moves is different from how a fidgety preadolescent moves. % though the terminology to define how the characteristics of these movement patterns differ is lacking. 

There is also a chance that patients within the same age group move differently possibly due to their cognitive state. Preadolescents who have ADHD likely become bored and fidgety in the MR scanner at different rates then their non-ADHD counterparts. Adults suffering from dementia may have more difficulty remaining still for the duration of a scan than adults from similar demographics with no dementia.

These patterns are essentially signals specific to different categories of patients. Machine learning techniques are useful for identifying patterns in signals from different sources. In addition to the motion metrics identified in the previous section, we will also use demographic and clinical data as features for our machine learning models. 

The goal of applying machine learning to identify population level motion patterns lends itself well to unsupervised machine learning techniques. Unsupervised learning techniques group samples from a population based on the patterns in their features. They do not use information about any known groups in the population to inform their classification processes. In this section, we discuss several different unsupervised machine learning techniques used to measure degrees of association within subgroups of a data set.

\subsection{K-means Clustering}

K-means clustering divides a group of data samples with $n$ features into $k$ groups based on each sample's distance from the average value of the group \cite{Hartigan1979}, \cite{macqueen1967}. In k-means clustering, the features of a set of data are viewed as the locations of each data sample in \textit{n}-dimensional space. In this space, \textit{k} cluster centroids are initially distrubuted. The distribution pattern can place the centroids either randomly between data samples or using randomly selected data points.

After the locations of the cluster centroids are initialized, the distance between each sample and each centroid is calculated. Each sample is assigned to the cluster represented by the centroid closest to it. Once the clusters are defined, the location of the centroid of each cluster is recalculated. The new centroid location is the mean of the locations of all samples in its cluster. The distance between each sample and each cluster centroid is recalculated, samples are reassigned to their closest cluster centroid, and the centroid of each cluster is recalculated. This process continues until a stopping criteria is fulfilled. With most unsupervised machine learning methods, the stopping criteria is that the classifications of the model do not change for a certain number of iterations. However, a maximum number of iterations is imposed on the learning process to prevent a model from running indefinitely. As a result, it is possible for a model to ``time out'' before reaching a stable state.

There are many variations of k-means clustering. For example, k-medians follows the same steps as k-means, but uses the median of the known data points in a cluster as the new centroid for that cluster \cite{Juan1998}. Another variation called k-mediods uses the data point closest to the center of the cluster as the new cluster centroid rather than a descriptive statistic of the cluster \cite{Kaufman1987}.

One of the major limitations of k-means clustering is that the number of clusters must be given to the model. It is difficult to know how many clusters are needed to adequately represent subgroups within a data set. If too many clusters are used, the groups identified by the algorithm will be more granular than they should be; however, using too few clusters will produce large groups which mask distinct subgroups. 



\subsection{Spectral Clustering}

While spectral clustering is related to k-means clustering, it approaches the problem of identifying associations in a group of data from a different perspective. Spectral clustering treats each data point in a sample as a node in a graph. The connections between data points are characterized by the adjacency matrix and the degree matrix of the graph. These two matrices are used to calculate the Laplacian matrix of the graph, whose properties are used to identify clusters. All three matrices are $n$x$n$ matrices, where $n$ is the number of data points in the sample. 

Herein, we discuss spectral clustering when the data can be represented using a simple graph. As such, certain mathematical shortcuts can be employed to simplify certain computations. A more general mathematical approach has been discussed by Ng, Jordan, and Weiss \cite{Ng2002}.

The adjacency matrix specifies the strength of the connection between the nodes represented by the rows and columns of the matrix. For data that does not begin in graph form, algorithms such as k-nearest neighbors can be used to generate the adjacency matrix. In the adjacency matrix, each entry $i, j$ contains the weight of the connection between node $i$ and node $j$. If the edges are unweighted, the value of the entry is either 0 or 1. If the graph is undirected, the value of entry $i, j$ is the same as the value of entry $j, i$. All entries where $i=j$ should be 0, unless node $i$ has a self-loop.

The degree matrix is a diagonal matrix which represents the number of edges connected to each node. If the graph is directed, the directionality of the degree matrix must be specified: a directed connection from node $a$ to node $b$ contributes to the count for node $a$ if the degree matrix counts the number of edges that begin at each node (outdegree), but contributes to the count for node $b$ if the degree matrix counts the number of terminating edges at each node (indegree). In the case of an undirected graph, the connections include all edges that begin or terminate at a node. To summarize, in an directed graph, each edge contributes to only one node count while in an undirected graph each edge contributes to both nodes.

The adjacency matrix and the degree matrix are used together to construct the Laplacian matrix of the graph. This calculation of the normal Laplacian for a simple graph (undirected and containing no loops) is straightforward: the adjacency matrix is subtracted from the degree matrix. The resulting matrix has the following properties:
\begin{itemize}
\item The diagonals are the number of connections per node less the number of self-connections
\item All off-diagonal values are the negative of the weight connecting node $i$ to node $j$.
\end{itemize}
It is important to note that if the graph in question contains loops or is directional, other methods must be used to calculate the Laplacian matrix. 

The Laplacian matrix can be used to explore many properties of a graph. In particular, the eigenvalues of the Laplacian matrix are informative about the number of connected components in the graph. Connected components are areas of the network that are connected to each other but not anything outside that component. Each connected component is not its own cluster, though: the connected components could be large and contain smaller sets of connected nodes that are good options for clusters.

To determine the number of clusters in the graph, the eigenvalues of the Laplacian matrix are sorted in increasing order. The number of zero-valued eigenvalues is the number of connected components in the graph. Eigenvalues close to zero suggest weak edges preventing some connected component from being two separate components. Manually examining these eigenvalues before performing spectral clustering can be informative about the number of clusters to create: the number of values below the first large gap between the eigenvalues are the number of clusters, $k$. The eigenvectors associated with these $k$ eigenvalues are used as a lower-dimensional representation of the data in the graph. Performing $k$-means clustering on this data produces the labels for the clusters within the data that are not linearly separable otherwise.

\textbf{Strengths of spectral clustering}

\textbf{Weaknesses of spectral clustering}

\subsection{Agglomerative Clustering}

Agglomerative clustering is a specific type of hierarchical clustering which builds a tree of similarities between data samples from the ``bottom up'' \cite{Ward1963}. The data samples in agglomerative clustering are also viewed as distinct points in $n$-dimensional space, but the number of groups to identify is not specified. 

First, the distance from every data sample to every other data sample is calculated. The two data points that are closest together in terms of some similarity metric are combined into a single cluster. In the [relationship tree] representing the similarities between all data samples, a node is created and the joined data points are connected to that node. That node or cluster is treated as an intermediate data sample. The distance from the new ``data sample'' to every other data sample is calculated and the two closest data samples are again combined into another intermediate sample. A node representing the new cluster is added to the [relationship tree] and the data sample or samples merged into the cluster are connected to the node. The process of combining data points into clusters based on similarity to other data points terminates when all data points and clusters have been combined. 

The results of agglomerative clustering can be interpreted by traversing the [relationship tree]. The [relationship tree] recorded the history of which nodes were merged into which clusters at each stage. Due to the nature of agglomerative clustering, these stages can be viewed as distinct levels in the tree. Beginning at the final node (the root) of the tree, the granularity of the clusters can be explored. At the top level, there is only one cluster, but at the second to last level of the tree there will be two clusters, at the third level there will be three clusters, and so on. How each cluster grew can reveal information about the relationships between the data samples within that cluster.

\subsection{Visualizing Clustering Results} 

The results of unsupervised clustering algorithms can be visualized to illustrate how the computer chose each group of samples. Depending on the number of features $n$ for each data sample, a dimensionality reduction method may be needed to transform the location of the data sample in $n$-dimensional feature space to a more easily visualized 2-dimensional or 3-dimensional space.

Dimensionality reduction methods include principle component analysis (PCA), TSNE, and XXXXXX.

Principle component analysis is a multivariate statistical technique that can be used to transform a set of variables with some degree of intercorrelation into a set of new, independent, orthogonal variables \cite{Abdi2010}. These variables are called principle components of the data set. The principle components are ordered with respect to the amount of variance in the data set that can be projected onto each component. In general, PCA fits an $p$-dimensional ellipsoid to a data set with $n$ features such that $p < n$. Each axis of the ellipsoid represents a single principle component. 

It is important to note that prior to the application of PCA, the data must be normalized. Normalizing the data allows different features to be compared on the same scale.

The first two or three principle components can be used to plot the results of a clustering algorithm in 2D or 3D space. An example of plotting clustering results using PCA can be seen in Figure [INSERT].

\textbf{TSNE}

Agglomerative clustering also lends itself well to visualization via heatmap. The heatmap allows the researcher to see the distribution of feature values across the dataset and across visually prominent clusters. ``Eyeballing'' a heatmap is no substitution for performing statistical analyses, but it can provide a better sense of context than summary statistics.  

\section{Predicting Patient Outcomes Using Motion Patterns}

In addition to examining the patterns of patient motion using unsupervised machine learning techniques, these patterns will also be used with supervised machine learning techniques to determine the relationship between motion types and clinical outcomes. In this section, we first present several supervised machine learning methods and then discuss more generally the limitations of supervised machine learning and the metrics we will use to evaluate our models.

\subsection{Regression}

The first supervised machine learning method we discuss is regression. In general, regression maps a set of features to a set of outcomes. Each feature is weighted based on its contribution to the outcome. Features which are more relevant to the outcome have larger weights, while less important features have smaller weights. 

The simplest version of regression is linear regression. Linear regression is used when the outcome being predicted has continuous values: a common example would be using the size of a house to predict its cost. The cost, $y$, would be modeled as

\begin{equation}
y = w_0 + w*x
\end{equation}

\noindent where $w$ is the weight assigned to the feature $x$, which is the size of the house, and $w_0$ is the weight for the bias in the model. As more features are added to the model, this equation generalizes to 

\begin{equation}
y = w_0 + \sum_{i \in N} w_i*x_i
\end{equation}

\noindent where $w_i$ is the weight for feature $i$, $x_i$ in the set of $N$ features. 

Alternatively, if the goal was to predict whether a house was owned or rented, linear regression would be a poor model choice. The goal of this problem is to identify a nominal class, not a value in a continuous interval. This type of problem is better suited for logistic regression.

Logistic regression takes the equation for linear regression and passes it through the logistic function. % BUT WHY
The logistic function is 

\begin{equation}
f(\pi) = \frac{1}{1+e^{\pi}}
\end{equation}

\noindent which means that a logistic regression models takes the form

\begin{equation}
y = \frac{1}{1+e^{(w_0 + \sum_{i \in N} w_i*x_i)}}
\end{equation}

This form of a logistic regression model is for binary, nominal outcomes, though multinomial logistic regression can model three or more outcomes and ordinal logistic regression can model ordered, discrete outcomes. For the purposes of this document, when we say logistic regression, we mean the form which models binary, nominal outcomes. 

\textbf{STRENGTHS AND WEAKNESSES} 

\subsection{Support Vector Machine}

\subsection{Expectation Maximization}

\subsection{LSTM Recurrent Neural Network}

Another approach to analyzing these signals is regression. Regression models the relationships between a set of independent features and an outcome or set of outcomes. For example, the linear regression could be used to evaluate the relationship between motion metrics and the severity of neurodevelopmental outcomes or patient age. 

In addition to machine learning and regression, other techniques from the biomedical imaging and computer vision domains may be used. Supervised machine learning models may also be trained to predict a clinical or behavioral outcome based on a patient's image features.

\subsection{Application of Supervised Machine Learning}

Generally, the outcomes of interest when applying supervised machine learning to medical data are some definition of normal and abnormal. We choose to perform two different analyses bases on two definitions of normal. 

The first definition of normal is that enough motion can be removed from the image that the image is usable. The abnormal label is that the image cannot be recovered based on the patient's motion patterns.

The second definition of normal is that the patient is healthy. We choose to identify the opposite label of ``the patient is healthy'' as ``the patient \textbf{may} not be healthy'' because of the heterogeneity of our data. CHD is a heterogeneous disease with many presentation types, and the neurodevelopmental disorders add another degree of granularity and complexity to a subject's clinical diagnosis. While it would be impressive to be able to build a clinical decision support tool that can diagnose a patient as having a particular form of CHD accompanied by a specific neurocognitive disorder, this goal is not the purpose of this project.

If a machine learning model reaches 100\% accuracy on both training and test data sets, data scientists should immediately assume something has gone wrong either with the model itself or with the training and testing data. Current machine learning models suffer from the difficulty of balancing two sources of error: bias and variance. Bias is the degree to which the machine learning model matches the underlying model of the training data. Variance is the breadth of the distribution of the data from the population of interest covered by the training data. Models with low bias and high variance overfit the training data: they model the training data well but generalize poorly to new data. Conversely, models with high bias and low variance underfit the training data: they fit the training data poorly, possibly because they learned noise in the training data rather than the signal. Underfitted models fail to capture the important signals from the training data and perform poorly overall.

A good model neither overfit nor underfits the training data. It has low bias and low variance, and the challenge of balancing these two sources of error has been discussed elsewhere but is important to address here to set realistic expectations about the training and testing classifications of a model. Ideally, the model will classify both training and testing data well, but it is not possible with current techniques and data availability for a model to have perfect classification of every data sample. 

The ``wellness''/``goodness'' of a binary classification model is determined using a truth table. A truth table is a $2*2$ table filled with the number of occurrences where data was classified correctly and incorrectly as belonging to each class. An example table can be seen in Table \ref{ch4:tab:truthtable}.

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[]
\caption{An example of a truth table for a binary classifier predicting the presence or absence of a condition.}
\label{ch4:tab:truthtable}
\begin{tabular}{cc|c|c|}
\cline{3-4}
\multicolumn{2}{c}{\multirow{2}{*}{}}                                                & \multicolumn{2}{|c|}{\textit{Actual}}               \\ \cline{3-4} 
\multicolumn{2}{c|}{}                                                                 & \textbf{Condition True} & \textbf{Condition False} \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{\textit{Predicted}}} & \textbf{Condition True}  & True Positive (TP)      & False Positive (FP)      \\ \cline{2-4} 
\multicolumn{1}{|c|}{}                                    & \textbf{Condition False} & False Negative (FN)     & True Negative (TN)       \\ \hline
\end{tabular}
\end{table}

Various metrics can be calculated from the truth table. Accuracy, for example, is a measure of how many data samples were classified correctly:

\begin{equation}
A = \frac{TP+TN}{TP+TN+FP+FN}
\end{equation}

\noindent Other metrics such as sensitivity and specificity evaluate how well a model performed at correctly identifying data samples from each known class where sensitivity is calculated as

\begin{equation}
000
\end{equation}

These metrics are also known as the true positive and true negative rates. Another metric, precision, evaluates how many classifications of the model into a single class actually belong in that class.

These metrics are independently informative about different aspects of the model, but during training one metric is used to evaluate a model's performance. We choose to use the balanced F1 score to evaluate the success of our supervised learning models. The balanced F1 score is calculated as:

\begin{equation}
F1 = \frac{}{}
\end{equation}

\section{Describing Motion Patterns}

In previous sections we describe practical knowledge about how fetal, neonatal, preadolescent, and adult patients move in different ways during MRI scans. We wish to quantify these movement patterns using the metrics described in Chapter \ref{ch:methods} and identify appropriate terminology that can be used to describe them.


\subsection{Supervised Learning Techniques}

Supervised learning techniques use features of a collection of data samples

Regression: logistic to identify healthy vs. CHD, linear to predict clinical values

K-nearest neighbors to identify patients with similar motion patterns







\subsection{Demographic-Related Motion Patterns} % in different populations to formally describe age-group or clinical status related motion patterns.

%The purpose of this experiment is to address the following questions. Are there any patterns in motion that are similar (a) within age groups, (b) within groups scanned at the same site, or (c) within broad clinical groups? Are these patterns due to spurious signals?

To ensure that there are no confounding signals in our datasets, we first use unsupervised machine learning techniques to identify correlations between subject images and their demographic data. The techniques we will use are several types of clustering (agglomerative, k-means, and spectral) as well as principle component analysis (PCA) and regression. Features of the images before and after registration will be used as training data for each model and different demographic features will be used as the true classes. %The demographic data for each subject includes the subject's age at the time of scan, gender, race, dominant hand, and scan site. (NOTE: THAT SENTENCE IS FOR MULTISITE STUDY DATA, NEED TO SPECIFY, ALSO NEED TO GET ALL CLINICAL DATA.)

\textbf{Phantom Images.} The phantom images are included in this analysis, though no significant results are expected other than potential site specific results.

\textbf{Clinical Cohorts.} Any demographic features which influence the division of patients into groups will be reported and accounted for during later analyses. After identifying and accounting for demographic groups, we will expand the analysis to clinical and behavioral outcomes.


\subsection{Clinical-Related Motion Patterns} %Employ machine learning techniques to (a) measure the impact of motion on image harmonization in multi-center studies, and (b) evaluate the relationship between motion and cognitive, clinical, and behavioral outcomes of CHD patients.

In addition to evaluating the effects of the DAG-based framework within the context of a motion correction pipeline, the registered images are used to explore the relationship between motion and clinical outcomes. Unsupervised machine learning techniques such as agglomerative clustering and k-means clustering are applied to the data. The results of the clustering techniques elucidate whether there are patterns in motion specific to certain patient groups. These groups could include patients with similar clinical outcomes, patients from the same site, or potentially other clinical or demographic groups.

%\section{Other potential areas I'm thinking about}

%\textbf{Machine Learning for Optimal Motion Correction} Start with a classification module for identifying severity of motion between template volume, previous volume(s), and current volume. The classifications will be based either on the patterns identified in Aim 2, or on the positional and signal change differences between the volumes of interest.

%After the severity of the motion reflected in a volume is determined...

%\textbf{Aim 4: Does Motion Correction Recover True Signal?} Hinted at earlier in first section of chapter, should it get its own section?